{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacred import Experiment\n",
    "from sacred.commands import print_config\n",
    "from sacred.observers import FileStorageObserver\n",
    "\n",
    "ex = Experiment('PHME20', interactive=True)\n",
    "# ex.observers.append(FileStorageObserver('./lgbm_logs/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.config\n",
    "def configuration_settings():\n",
    "    fill_missing_ = True\n",
    "    scale_type = \"standard\"\n",
    "    window_size_ = 5\n",
    "    train_model = True\n",
    "    eval_model = True\n",
    "    subsample = 10 # for sampling\n",
    "    stride = 5 # for stride\n",
    "    \n",
    "    num_leaves_ = -1\n",
    "    learning_rate_ = 0.1\n",
    "    n_estimators_ = 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import data\n",
    "data_df_1 = pd.read_csv(\"../../data/training_validation_1.csv\")\n",
    "data_df_2 = pd.read_csv(\"../../data/training_validation_2.csv\")\n",
    "data_df_3 = pd.read_csv(\"../../data/model_refinement.csv\")\n",
    "\n",
    "train_df = pd.concat([data_df_1, data_df_2, data_df_3], axis=0) # Merge data frames\n",
    "# train_df = data_df_2.filter(regex=\"vCnt|value\")\n",
    "\n",
    "train_df['runId'] = 1000 * train_df['class'] + train_df['run']\n",
    "\n",
    "labels = train_df['class']\n",
    "runs = train_df['runId']\n",
    "\n",
    "run_df = train_df[['class', 'runId']].copy()\n",
    "run_df.drop_duplicates(inplace=True)\n",
    "run_df.reset_index(inplace=True)\n",
    "del run_df['index']\n",
    "\n",
    "# del train_df['class']\n",
    "del train_df['run']\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% skip \n",
    "sensor_list = list(train_df.columns)\n",
    "sensor_list.remove('runId')\n",
    "sensor_list.remove('class')\n",
    "len(sensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_list_xgb = ['Humidity_value',\n",
    " 'TotalMemoryConsumption_value',\n",
    " 'SmartMotorSpeed_value',\n",
    " 'TotalCpuLoadNormalized_value',\n",
    " 'Temperature_value',\n",
    " 'ProcessMemoryConsumption_value',\n",
    " 'DurationRobotFromFeederToTestBench_value',\n",
    " 'CpuTemperature_value',\n",
    " 'FuseCycleDuration_value',\n",
    " 'FuseTestResult_vCnt',\n",
    " 'IntensityTotalThermoImage_value',\n",
    " 'Pressure_value',\n",
    " 'ValidFrame_vCnt',\n",
    " 'DurationPickToPick_value',\n",
    " 'DurationTestBenchClosed_value',\n",
    " 'VacuumValveClosed_value',\n",
    " 'ProcessCpuLoadNormalized_value',\n",
    " 'FuseOutsideOperationalSpace_vCnt',\n",
    " 'Pressure_vCnt',\n",
    " 'FeederAction2_vCnt',\n",
    " 'FuseTestResult_value',\n",
    " 'NumberFuseEstimated_value',\n",
    " 'Vacuum_vCnt',\n",
    " 'LightBarrierActiveTaskDuration1_value',\n",
    " 'FusePicked_vCnt',\n",
    " 'DurationTestBenchClosed_vCnt',\n",
    " 'FeederAction4_vCnt',\n",
    " 'DurationPickToPick_vCnt',\n",
    " 'EPOSCurrent_value',\n",
    " 'VacuumFusePicked_value',\n",
    " 'FuseHeatSlopeOK_value',\n",
    " 'EPOSCurrent_vCnt']\n",
    "\n",
    "len(sensor_list_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_list_lgbm = ['TotalMemoryConsumption_value',\n",
    " 'Humidity_value',\n",
    " 'Temperature_value',\n",
    " 'ProcessMemoryConsumption_value',\n",
    " 'TotalCpuLoadNormalized_value',\n",
    " 'SmartMotorSpeed_value',\n",
    " 'FuseCycleDuration_value',\n",
    " 'NumberFuseDetected_value',\n",
    " 'DurationRobotFromFeederToTestBench_value',\n",
    " 'Pressure_value',\n",
    " 'LightBarrierPassiveTaskDuration1_vCnt',\n",
    " 'FeederBackgroundIlluminationIntensity_value',\n",
    " 'Vacuum_value',\n",
    " 'Pressure_vCnt',\n",
    " 'VacuumFusePicked_vCnt',\n",
    " 'ProcessCpuLoadNormalized_value',\n",
    " 'DurationPickToPick_vCnt',\n",
    " 'EPOSPosition_value',\n",
    " 'NumberFuseEstimated_value',\n",
    " 'TemperatureThermoCam_value',\n",
    " 'VacuumValveClosed_vCnt',\n",
    " 'FusePicked_vCnt',\n",
    " 'FusePicked_value',\n",
    " 'FuseHeatSlopeNOK_value',\n",
    " 'FuseCycleDuration_vCnt',\n",
    " 'FuseHeatSlopeOK_value',\n",
    " 'IntensityTotalThermoImage_value',\n",
    " 'FuseIntoFeeder_vCnt',\n",
    " 'ValidFrameOptrisPIIRCamera_vCnt',\n",
    " 'FeederAction4_vCnt']\n",
    "\n",
    "len(sensor_list_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_list = sensor_list_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from ngboost import NGBClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def create_sequence(sequence, n_steps):\n",
    "    X = list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x = sequence[i:end_ix]\n",
    "        X.append(seq_x)\n",
    "    return np.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_for_run(df, ws):\n",
    "#     data_data = np.empty((0, ws * len(sensor_list))) # for 1D\n",
    "#     data_data = np.empty((0, ws, len(sensor_list))) # for 2D\n",
    "#     data_data = np.empty((0, len(sensor_list), ws)) # for 2D\n",
    "#     label_data = np.empty((0, 1))\n",
    "\n",
    "    sensors_df = df.filter(sensor_list)\n",
    "\n",
    "    # Calculate seq of windows_size len\n",
    "    seq = create_sequence(sensors_df.values, n_steps=ws)\n",
    "#     seq = np.transpose(seq, axes=(0, 2, 1))\n",
    "    seq_count = seq.shape[0]\n",
    "    seq = seq.reshape((seq_count, -1)) # for 1D\n",
    "\n",
    "    # add new seq to data_data array\n",
    "#     data_data = np.vstack((data_data, seq))\n",
    "\n",
    "    # Calculate RULS\n",
    "    labels = df['class'].values[:seq_count]\n",
    "\n",
    "    # add rul to rul_data array\n",
    "#     rul_data = np.vstack((rul_data, ruls))\n",
    "\n",
    "# TODO: What is RUL_Max in this context?\n",
    "\n",
    "#     print (\"Shape:\", seq.shape, labels.shape)\n",
    "    return seq, labels\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "\n",
    "# Main sensor list. \n",
    "# List shall include other features such as operating conditions. \n",
    "_subsample = -1\n",
    "_stride = -1\n",
    "\n",
    "# scale_type = \"standard\"\n",
    "# window_size = 50\n",
    "# cv_fold = 3\n",
    "\n",
    "# train_model = True\n",
    "# eval_model = True\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: X_t, X_tp1, y_t, y_tp1 should be calculated per run.  \n",
    "# TODO: Then should be merged into one X_t, X_tp1, y_t, y_tp1.\n",
    "def create_datasets(df, ws):\n",
    "    \n",
    "    run_list = df['runId'].unique()\n",
    "\n",
    "    X_df_list = []\n",
    "    y_df_list = []\n",
    "    \n",
    "    for r in run_list:\n",
    "        r_df = df[df['runId'] == r]\n",
    "#         print (\"--> r: \", r, r_df.shape)\n",
    "        sensor_data, label_data = create_dataset_for_run(r_df, ws)\n",
    "\n",
    "        # Post Processing for the model\n",
    "\n",
    "        # Padding for model input \n",
    "        padded_sensor_data = sensor_data.copy() #np.hstack((sensor_data, np.zeros((sensor_data.shape[0], 2)))) # for AE     \n",
    "\n",
    "        # Calculate X(t) and X(t+1) for model input/output \n",
    "        X_t = padded_sensor_data[:]\n",
    "\n",
    "        # Calculate y(t) and y(t+1) for model input/output \n",
    "        y_t = label_data[:]\n",
    "\n",
    "        X_df_list.append(pd.DataFrame(X_t))\n",
    "        y_df_list.append(pd.DataFrame(y_t))\n",
    "    \n",
    "    X_t = pd.concat(X_df_list, axis=0) # Merge data frames\n",
    "    y_t = pd.concat(y_df_list, axis=0) # Merge data frames\n",
    "\n",
    "    return X_t.values, y_t.values.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = StratifiedKFold(n_splits=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillna_list = [True, False]\n",
    "ws_list = [1, 2, 3, 4, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "params_num_leaves = [5, 10, 15, 20, 30, 40, 50]\n",
    "param_learning_rate = [0.1, 0.01, 0.001]\n",
    "params_n_estimators = [100, 200, 300, 400, 500, 1000]\n",
    "\n",
    "total_runs = len(fillna_list) * len(ws_list) * len(params_num_leaves) * len(param_learning_rate)  * len(params_n_estimators)\n",
    "\n",
    "total_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_counter = 0\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "@ex.main\n",
    "def ex_main(_run, fill_missing_, scale_type, window_size_, train_model, eval_model, subsample, stride, num_leaves_, learning_rate_, n_estimators_):\n",
    "\n",
    "    global total_runs\n",
    "    global run_counter\n",
    "    global results_df\n",
    "    \n",
    "    print ('===========================================================================')\n",
    "    print ('Run:', run_counter+1, '/', total_runs)\n",
    "    print (\"Fill missing:\", fill_missing_, \"Window Size:\", window_size_, \"LGBM Params:\", num_leaves_, learning_rate_, n_estimators_)\n",
    "\n",
    "    run_counter += 1\n",
    "    \n",
    "    acc_sum = 0\n",
    "    f1_sum = 0\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "    for fold, (training_indices, validation_indices) in enumerate(cv.split(run_df['runId'], run_df['class'])):\n",
    "        print (\"--> Fold: \", fold)\n",
    "\n",
    "        training_runIds = run_df.loc[training_indices]['runId']\n",
    "        validation_runIds = run_df.loc[validation_indices]['runId']\n",
    "\n",
    "        X_train_df = train_df[train_df['runId'].isin(training_runIds)].copy()\n",
    "        X_val_df = train_df[train_df['runId'].isin(validation_runIds)].copy()\n",
    "\n",
    "        if (fill_missing_):\n",
    "            X_train_df.fillna(method='backfill', inplace=True)\n",
    "            X_val_df.fillna(method='backfill', inplace=True)\n",
    "\n",
    "            X_train_df.fillna(-1, inplace=True)\n",
    "            X_val_df.fillna(-1, inplace=True)\n",
    "\n",
    "        X_train, y_train = create_datasets(X_train_df, window_size_)\n",
    "        X_val, y_val = create_datasets(X_val_df, window_size_)\n",
    "\n",
    "    #     print (\"Data shape\", X_train_df.shape, X_val_df.shape)\n",
    "        print (\"Train data shape:\", X_train.shape, y_train.shape)\n",
    "        print (\"Val data shape:\", X_val.shape, y_val.shape)\n",
    "\n",
    "        model = LGBMClassifier(num_leaves=num_leaves_, learning_rate=learning_rate_, n_estimators=n_estimators_)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "#         m = np.argmax(model.feature_importances_)\n",
    "#         print (sensor_list[m], model.feature_importances_[m])\n",
    "\n",
    "        pred = model.predict(X_val)\n",
    "\n",
    "        acc_val = accuracy_score(pred, y_val)\n",
    "        f1_val = f1_score(pred, y_val, average='weighted')\n",
    "\n",
    "        acc_sum += acc_val\n",
    "        f1_sum += f1_val\n",
    "\n",
    "        print (\"Fold:\", fold, \"ACC:\", acc_val, \"F1:\", f1_val)\n",
    "\n",
    "    print ()\n",
    "    print (\"Avg ACC:\", acc_sum / 3.0, \"Avg F1:\", f1_sum / 3.0)\n",
    "\n",
    "    result = {\n",
    "        'ML_Algorithm': 'LGBM',\n",
    "        'Fill missing': fill_missing_, \n",
    "        'Window Size': window_size_, \n",
    "        'Params_num_leaves': num_leaves_, \n",
    "        'Params_learning_rate': learning_rate_, \n",
    "        'Params_n_estimators': n_estimators_,        \n",
    "        'ACC': acc_sum / 3.0,\n",
    "        'F1': f1_sum / 3.0,\n",
    "    }\n",
    "\n",
    "    results_df = results_df.append(result, ignore_index=True)\n",
    "    results_df.to_excel(\"lgbm_results.xlsx\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fnal in fillna_list:\n",
    "    for wsl in ws_list:\n",
    "        for pnl in params_num_leaves:\n",
    "            for plr in param_learning_rate:\n",
    "                for pne in params_n_estimators:\n",
    "                    ex.run(config_updates={\n",
    "                        'fill_missing_': fnal,\n",
    "                        'window_size_': wsl,\n",
    "                        'num_leaves_': pnl,\n",
    "                        'learning_rate_': plr,\n",
    "                        'n_estimators_': pne,\n",
    "                    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
