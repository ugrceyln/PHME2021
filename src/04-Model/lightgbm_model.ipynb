{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57971, 249)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### import data\n",
    "data_df_1 = pd.read_csv(\"../../data/training_validation_1.csv\")\n",
    "data_df_2 = pd.read_csv(\"../../data/training_validation_2.csv\")\n",
    "data_df_3 = pd.read_csv(\"../../data/model_refinement.csv\")\n",
    "train_df = pd.concat([data_df_1, data_df_2, data_df_3], axis=0) # Merge data frames\n",
    "# train_df = data_df_2.filter(regex=\"vCnt|value\")\n",
    "\n",
    "train_df['runId'] = 1000 * train_df['class'] + train_df['run']\n",
    "\n",
    "labels = train_df['class']\n",
    "runs = train_df['runId']\n",
    "\n",
    "run_df = train_df[['class', 'runId']].copy()\n",
    "run_df.drop_duplicates(inplace=True)\n",
    "run_df.reset_index(inplace=True)\n",
    "del run_df['index']\n",
    "\n",
    "# del train_df['class']\n",
    "del train_df['run']\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_list = list(train_df.columns)\n",
    "sensor_list.remove('runId')\n",
    "sensor_list.remove('class')\n",
    "len(sensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_list = list(train_df.filter(regex=\"vCnt|value\").columns)\n",
    "len(sensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "# from ngboost import NGBClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CpuTemperature_vMax</th>\n",
       "      <th>CpuTemperature_vMin</th>\n",
       "      <th>CpuTemperature_vStd</th>\n",
       "      <th>CpuTemperature_value</th>\n",
       "      <th>DurationPickToPick_vCnt</th>\n",
       "      <th>DurationPickToPick_vFreq</th>\n",
       "      <th>DurationPickToPick_vMax</th>\n",
       "      <th>DurationPickToPick_vMin</th>\n",
       "      <th>DurationPickToPick_vStd</th>\n",
       "      <th>DurationPickToPick_vTrend</th>\n",
       "      <th>...</th>\n",
       "      <th>VacuumValveClosed_vMin</th>\n",
       "      <th>VacuumValveClosed_vStd</th>\n",
       "      <th>VacuumValveClosed_vTrend</th>\n",
       "      <th>VacuumValveClosed_value</th>\n",
       "      <th>ValidFrame_vCnt</th>\n",
       "      <th>ValidFrame_vFreq</th>\n",
       "      <th>ValidFrameOptrisPIIRCamera_vCnt</th>\n",
       "      <th>ValidFrameOptrisPIIRCamera_vFreq</th>\n",
       "      <th>class</th>\n",
       "      <th>runId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.75</td>\n",
       "      <td>44.75</td>\n",
       "      <td>3.523729</td>\n",
       "      <td>47.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>11.457455</td>\n",
       "      <td>259.0</td>\n",
       "      <td>27.582899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.75</td>\n",
       "      <td>42.25</td>\n",
       "      <td>2.395308</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.198207</td>\n",
       "      <td>3.192</td>\n",
       "      <td>2.807</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.715812</td>\n",
       "      <td>0.112918</td>\n",
       "      <td>-0.013857</td>\n",
       "      <td>-0.580892</td>\n",
       "      <td>114.0</td>\n",
       "      <td>11.299041</td>\n",
       "      <td>273.0</td>\n",
       "      <td>27.058227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.50</td>\n",
       "      <td>42.00</td>\n",
       "      <td>2.085815</td>\n",
       "      <td>43.825000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.296778</td>\n",
       "      <td>3.230</td>\n",
       "      <td>3.106</td>\n",
       "      <td>0.051674</td>\n",
       "      <td>0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.721671</td>\n",
       "      <td>0.109421</td>\n",
       "      <td>-0.008111</td>\n",
       "      <td>-0.596008</td>\n",
       "      <td>114.0</td>\n",
       "      <td>11.277551</td>\n",
       "      <td>272.0</td>\n",
       "      <td>26.907842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.25</td>\n",
       "      <td>42.25</td>\n",
       "      <td>1.853375</td>\n",
       "      <td>45.200000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.298541</td>\n",
       "      <td>3.307</td>\n",
       "      <td>3.103</td>\n",
       "      <td>0.085391</td>\n",
       "      <td>0.031</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.745598</td>\n",
       "      <td>0.116748</td>\n",
       "      <td>-0.002082</td>\n",
       "      <td>-0.595118</td>\n",
       "      <td>114.0</td>\n",
       "      <td>11.344572</td>\n",
       "      <td>271.0</td>\n",
       "      <td>26.968238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.00</td>\n",
       "      <td>42.50</td>\n",
       "      <td>2.661766</td>\n",
       "      <td>45.700000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.298554</td>\n",
       "      <td>3.242</td>\n",
       "      <td>3.153</td>\n",
       "      <td>0.038577</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.720206</td>\n",
       "      <td>0.112639</td>\n",
       "      <td>-0.001516</td>\n",
       "      <td>-0.615755</td>\n",
       "      <td>113.0</td>\n",
       "      <td>11.245550</td>\n",
       "      <td>271.0</td>\n",
       "      <td>26.969415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CpuTemperature_vMax  CpuTemperature_vMin  CpuTemperature_vStd  \\\n",
       "0                56.75                44.75             3.523729   \n",
       "1                48.75                42.25             2.395308   \n",
       "2                47.50                42.00             2.085815   \n",
       "3                48.25                42.25             1.853375   \n",
       "4                50.00                42.50             2.661766   \n",
       "\n",
       "   CpuTemperature_value  DurationPickToPick_vCnt  DurationPickToPick_vFreq  \\\n",
       "0             47.833333                      0.0                  0.000000   \n",
       "1             45.000000                      2.0                  0.198207   \n",
       "2             43.825000                      3.0                  0.296778   \n",
       "3             45.200000                      3.0                  0.298541   \n",
       "4             45.700000                      3.0                  0.298554   \n",
       "\n",
       "   DurationPickToPick_vMax  DurationPickToPick_vMin  DurationPickToPick_vStd  \\\n",
       "0                      NaN                      NaN                      NaN   \n",
       "1                    3.192                    2.807                 0.192500   \n",
       "2                    3.230                    3.106                 0.051674   \n",
       "3                    3.307                    3.103                 0.085391   \n",
       "4                    3.242                    3.153                 0.038577   \n",
       "\n",
       "   DurationPickToPick_vTrend  ...  VacuumValveClosed_vMin  \\\n",
       "0                        NaN  ...                     NaN   \n",
       "1                      0.385  ...               -0.715812   \n",
       "2                      0.020  ...               -0.721671   \n",
       "3                      0.031  ...               -0.745598   \n",
       "4                     -0.036  ...               -0.720206   \n",
       "\n",
       "   VacuumValveClosed_vStd  VacuumValveClosed_vTrend  VacuumValveClosed_value  \\\n",
       "0                     NaN                       NaN                      NaN   \n",
       "1                0.112918                 -0.013857                -0.580892   \n",
       "2                0.109421                 -0.008111                -0.596008   \n",
       "3                0.116748                 -0.002082                -0.595118   \n",
       "4                0.112639                 -0.001516                -0.615755   \n",
       "\n",
       "   ValidFrame_vCnt  ValidFrame_vFreq  ValidFrameOptrisPIIRCamera_vCnt  \\\n",
       "0             89.0         11.457455                            259.0   \n",
       "1            114.0         11.299041                            273.0   \n",
       "2            114.0         11.277551                            272.0   \n",
       "3            114.0         11.344572                            271.0   \n",
       "4            113.0         11.245550                            271.0   \n",
       "\n",
       "   ValidFrameOptrisPIIRCamera_vFreq  class  runId  \n",
       "0                         27.582899      0      0  \n",
       "1                         27.058227      0      0  \n",
       "2                         26.907842      0      0  \n",
       "3                         26.968238      0      0  \n",
       "4                         26.969415      0      0  \n",
       "\n",
       "[5 rows x 249 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def create_sequence(sequence, n_steps):\n",
    "    X = list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x = sequence[i:end_ix]\n",
    "        X.append(seq_x)\n",
    "    return np.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_for_run(df, ws):\n",
    "#     data_data = np.empty((0, ws * len(sensor_list))) # for 1D\n",
    "#     data_data = np.empty((0, ws, len(sensor_list))) # for 2D\n",
    "#     data_data = np.empty((0, len(sensor_list), ws)) # for 2D\n",
    "#     label_data = np.empty((0, 1))\n",
    "\n",
    "    sensors_df = df.filter(sensor_list)\n",
    "\n",
    "    # Calculate seq of windows_size len\n",
    "    seq = create_sequence(sensors_df.values, n_steps=ws)\n",
    "#     seq = np.transpose(seq, axes=(0, 2, 1))\n",
    "    seq_count = seq.shape[0]\n",
    "    seq = seq.reshape((seq_count, -1)) # for 1D\n",
    "\n",
    "    # add new seq to data_data array\n",
    "#     data_data = np.vstack((data_data, seq))\n",
    "\n",
    "    # Calculate RULS\n",
    "    labels = df['class'].values[:seq_count]\n",
    "\n",
    "    # add rul to rul_data array\n",
    "#     rul_data = np.vstack((rul_data, ruls))\n",
    "\n",
    "# TODO: What is RUL_Max in this context?\n",
    "\n",
    "#     print (\"Shape:\", seq.shape, labels.shape)\n",
    "    return seq, labels\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = list(range(100))\n",
    "\n",
    "len(create_sequence(l, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: X_t, X_tp1, y_t, y_tp1 should be calculated per run.  \n",
    "# TODO: Then should be merged into one X_t, X_tp1, y_t, y_tp1.\n",
    "def create_datasets(df, ws):\n",
    "    \n",
    "    run_list = df['runId'].unique()\n",
    "\n",
    "    X_df_list = []\n",
    "    y_df_list = []\n",
    "    \n",
    "    for r in run_list:\n",
    "        r_df = df[df['runId'] == r]\n",
    "#         print (\"--> r: \", r, r_df.shape)\n",
    "        sensor_data, label_data = create_dataset_for_run(r_df, ws)\n",
    "\n",
    "        # Post Processing for the model\n",
    "\n",
    "        # Padding for model input \n",
    "        padded_sensor_data = sensor_data.copy() #np.hstack((sensor_data, np.zeros((sensor_data.shape[0], 2)))) # for AE     \n",
    "\n",
    "        # Calculate X(t) and X(t+1) for model input/output \n",
    "        X_t = padded_sensor_data[:]\n",
    "\n",
    "        # Calculate y(t) and y(t+1) for model input/output \n",
    "        y_t = label_data[:]\n",
    "\n",
    "        X_df_list.append(pd.DataFrame(X_t))\n",
    "        y_df_list.append(pd.DataFrame(y_t))\n",
    "    \n",
    "    X_t = pd.concat(X_df_list, axis=0) # Merge data frames\n",
    "    y_t = pd.concat(y_df_list, axis=0) # Merge data frames\n",
    "\n",
    "    return X_t.values, y_t.values.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = StratifiedKFold(n_splits=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Fold:  0\n",
      "Train data shape: (36045, 79) (36045,)\n",
      "Val data shape: (21926, 79) (21926,)\n",
      "TotalMemoryConsumption_value 2675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\KerasTF\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0 ACC: 0.5589254766031195 F1: 0.6485309085915042\n",
      "--> Fold:  1\n",
      "Train data shape: (39950, 79) (39950,)\n",
      "Val data shape: (18021, 79) (18021,)\n",
      "Humidity_value 3117\n",
      "Fold: 1 ACC: 0.43482603629099387 F1: 0.3915818123078961\n",
      "--> Fold:  2\n",
      "Train data shape: (39947, 79) (39947,)\n",
      "Val data shape: (18024, 79) (18024,)\n",
      "Humidity_value 3411\n",
      "Fold: 2 ACC: 0.6804260985352862 F1: 0.6650040088859027\n",
      "\n",
      "Avg ACC: 0.41854440285734995 Avg F1: 0.4262791824463258\n",
      "Wall time: 43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "acc_sum = 0\n",
    "f1_sum = 0\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "for fold, (training_indices, validation_indices) in enumerate(cv.split(run_df['runId'], run_df['class'])):\n",
    "    print (\"--> Fold: \", fold)\n",
    "    \n",
    "    training_runIds = run_df.loc[training_indices]['runId']\n",
    "    validation_runIds = run_df.loc[validation_indices]['runId']\n",
    "    \n",
    "    X_train_df = train_df[train_df['runId'].isin(training_runIds)].copy()\n",
    "    X_val_df = train_df[train_df['runId'].isin(validation_runIds)].copy()\n",
    "\n",
    "    X_train, y_train = create_datasets(X_train_df, 1)\n",
    "    X_val, y_val = create_datasets(X_val_df, 1)\n",
    "    \n",
    "#     print (\"Data shape\", X_train_df.shape, X_val_df.shape)\n",
    "    print (\"Train data shape:\", X_train.shape, y_train.shape)\n",
    "    print (\"Val data shape:\", X_val.shape, y_val.shape)\n",
    "    \n",
    "    model = LGBMClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    m = np.argmax(model.feature_importances_)\n",
    "    print (sensor_list[m], model.feature_importances_[m])\n",
    "    \n",
    "    pred = model.predict(X_val)\n",
    "    \n",
    "    acc_val = accuracy_score(pred, y_val)\n",
    "    f1_val = f1_score(pred, y_val, average='weighted')\n",
    "    \n",
    "    acc_sum += acc_val\n",
    "    f1_sum += f1_val\n",
    "    \n",
    "    print (\"Fold:\", fold, \"ACC:\", acc_val, \"F1:\", f1_val)\n",
    "\n",
    "print ()\n",
    "print (\"Avg ACC:\", acc_sum / 4.0, \"Avg F1:\", f1_sum / 4.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "acc_sum = 0\n",
    "f1_sum = 0\n",
    "\n",
    "cv = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "\n",
    "for fold, (training_indices, validation_indices) in enumerate(cv.split(run_df['runId'], run_df['class'])):\n",
    "    print (\"--> Fold: \", fold)\n",
    "    \n",
    "    training_runIds = run_df.loc[training_indices]['runId']\n",
    "    validation_runIds = run_df.loc[validation_indices]['runId']\n",
    "    \n",
    "    X_train_df = train_df[train_df['runId'].isin(training_runIds)].copy()\n",
    "    X_val_df = train_df[train_df['runId'].isin(validation_runIds)].copy()\n",
    "\n",
    "    X_train, y_train = create_datasets(X_train_df, 3)\n",
    "    X_val, y_val = create_datasets(X_val_df, 3)\n",
    "    \n",
    "    print (\"Data shape\", X_train_df.shape, X_val_df.shape)\n",
    "    print (\"Train data shape:\", X_train.shape, y_train.shape)\n",
    "    print (\"Val data shape:\", X_val.shape, y_val.shape)\n",
    "    \n",
    "    model = LGBMClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    m = np.argmax(model.feature_importances_)\n",
    "    print (sensor_list[m], model.feature_importances_[m])\n",
    "    \n",
    "    pred = model.predict(X_val)\n",
    "    \n",
    "    acc_val = accuracy_score(pred, y_val)\n",
    "    f1_val = f1_score(pred, y_val, average='weighted')\n",
    "    \n",
    "    acc_sum += acc_val\n",
    "    f1_sum += f1_val\n",
    "    \n",
    "    print (\"Fold:\", fold, \"ACC:\", acc_val, \"F1:\", f1_val)\n",
    "\n",
    "print ()\n",
    "print (\"Avg ACC:\", acc_sum / 4.0, \"Avg F1:\", f1_sum / 4.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "acc_sum = 0\n",
    "f1_sum = 0\n",
    "\n",
    "cv = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "\n",
    "for fold, (training_indices, validation_indices) in enumerate(cv.split(run_df['runId'], run_df['class'])):\n",
    "    print (\"--> Fold: \", fold)\n",
    "    \n",
    "    training_runIds = run_df.loc[training_indices]['runId']\n",
    "    validation_runIds = run_df.loc[validation_indices]['runId']\n",
    "    \n",
    "    X_train_df = train_df[train_df['runId'].isin(training_runIds)].copy()\n",
    "    X_val_df = train_df[train_df['runId'].isin(validation_runIds)].copy()\n",
    "\n",
    "    X_train_df.fillna(method='backfill', inplace=True)\n",
    "    X_val_df.fillna(method='backfill', inplace=True)\n",
    "\n",
    "    X_train_df.fillna(-1, inplace=True)\n",
    "    X_val_df.fillna(-1, inplace=True)\n",
    "\n",
    "    X_train, y_train = create_datasets(X_train_df, 25)\n",
    "    X_val, y_val = create_datasets(X_val_df, 25)\n",
    "    \n",
    "    print (\"Train data shape:\", X_train.shape, y_train.shape)\n",
    "    print (\"Val data shape:\", X_val.shape, y_val.shape)\n",
    "\n",
    "    pca_model = PCA(n_components=50)\n",
    "    \n",
    "    X_train = pca_model.fit_transform(X_train)\n",
    "    X_val = pca_model.transform(X_val)\n",
    "\n",
    "    \n",
    "#     print (\"Data shape\", X_train_df.shape, X_val_df.shape)\n",
    "    print (\"Train data shape:\", X_train.shape, y_train.shape)\n",
    "    print (\"Val data shape:\", X_val.shape, y_val.shape)\n",
    "    \n",
    "    model = LGBMClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    m = np.argmax(model.feature_importances_)\n",
    "    print (sensor_list[m], model.feature_importances_[m])\n",
    "    \n",
    "    pred = model.predict(X_val)\n",
    "    \n",
    "    acc_val = accuracy_score(pred, y_val)\n",
    "    f1_val = f1_score(pred, y_val, average='weighted')\n",
    "    \n",
    "    acc_sum += acc_val\n",
    "    f1_sum += f1_val\n",
    "    \n",
    "    print (\"Fold:\", fold, \"ACC:\", acc_val, \"F1:\", f1_val)\n",
    "\n",
    "print ()\n",
    "print (\"Avg ACC:\", acc_sum / 4.0, \"Avg F1:\", f1_sum / 4.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "acc_sum = 0\n",
    "f1_sum = 0\n",
    "\n",
    "cv = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "\n",
    "for fold, (training_indices, validation_indices) in enumerate(cv.split(run_df['runId'], run_df['class'])):\n",
    "    print (\"--> Fold: \", fold)\n",
    "    \n",
    "    training_runIds = run_df.loc[training_indices]['runId']\n",
    "    validation_runIds = run_df.loc[validation_indices]['runId']\n",
    "    \n",
    "    X_train_df = train_df[train_df['runId'].isin(training_runIds)].copy()\n",
    "    X_val_df = train_df[train_df['runId'].isin(validation_runIds)].copy()\n",
    "\n",
    "    X_train_df.fillna(method='backfill', inplace=True)\n",
    "    X_val_df.fillna(method='backfill', inplace=True)\n",
    "\n",
    "    X_train_df.fillna(-1, inplace=True)\n",
    "    X_val_df.fillna(-1, inplace=True)\n",
    "\n",
    "    X_train, y_train = create_datasets(X_train_df, 25)\n",
    "    X_val, y_val = create_datasets(X_val_df, 25)\n",
    "    \n",
    "    print (\"Train data shape:\", X_train.shape, y_train.shape)\n",
    "    print (\"Val data shape:\", X_val.shape, y_val.shape)\n",
    "\n",
    "    pca_model = PCA(n_components=250)\n",
    "    \n",
    "    X_train = pca_model.fit_transform(X_train)\n",
    "    X_val = pca_model.transform(X_val)\n",
    "\n",
    "    \n",
    "#     print (\"Data shape\", X_train_df.shape, X_val_df.shape)\n",
    "    print (\"Train data shape:\", X_train.shape, y_train.shape)\n",
    "    print (\"Val data shape:\", X_val.shape, y_val.shape)\n",
    "    \n",
    "    model = LGBMClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    m = np.argmax(model.feature_importances_)\n",
    "    print (sensor_list[m], model.feature_importances_[m])\n",
    "    \n",
    "    pred = model.predict(X_val)\n",
    "    \n",
    "    acc_val = accuracy_score(pred, y_val)\n",
    "    f1_val = f1_score(pred, y_val, average='weighted')\n",
    "    \n",
    "    acc_sum += acc_val\n",
    "    f1_sum += f1_val\n",
    "    \n",
    "    print (\"Fold:\", fold, \"ACC:\", acc_val, \"F1:\", f1_val)\n",
    "\n",
    "print ()\n",
    "print (\"Avg ACC:\", acc_sum / 4.0, \"Avg F1:\", f1_sum / 4.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "acc_sum = 0\n",
    "f1_sum = 0\n",
    "\n",
    "cv = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "\n",
    "for fold, (training_indices, validation_indices) in enumerate(cv.split(run_df['runId'], run_df['class'])):\n",
    "    print (\"--> Fold: \", fold)\n",
    "    \n",
    "    training_runIds = run_df.loc[training_indices]['runId']\n",
    "    validation_runIds = run_df.loc[validation_indices]['runId']\n",
    "    \n",
    "    X_train_df = train_df[train_df['runId'].isin(training_runIds)].copy()\n",
    "    X_val_df = train_df[train_df['runId'].isin(validation_runIds)].copy()\n",
    "\n",
    "    X_train_df.fillna(method='backfill', inplace=True)\n",
    "    X_val_df.fillna(method='backfill', inplace=True)\n",
    "\n",
    "    X_train_df.fillna(-1, inplace=True)\n",
    "    X_val_df.fillna(-1, inplace=True)\n",
    "\n",
    "    X_train, y_train = create_datasets(X_train_df, 30)\n",
    "    X_val, y_val = create_datasets(X_val_df, 30)\n",
    "    \n",
    "    print (\"Train data shape:\", X_train.shape, y_train.shape)\n",
    "    print (\"Val data shape:\", X_val.shape, y_val.shape)\n",
    "\n",
    "    pca_model = PCA(n_components=250)\n",
    "    \n",
    "    X_train = pca_model.fit_transform(X_train)\n",
    "    X_val = pca_model.transform(X_val)\n",
    "\n",
    "    \n",
    "#     print (\"Data shape\", X_train_df.shape, X_val_df.shape)\n",
    "    print (\"Train data shape:\", X_train.shape, y_train.shape)\n",
    "    print (\"Val data shape:\", X_val.shape, y_val.shape)\n",
    "    \n",
    "    model = LGBMClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    m = np.argmax(model.feature_importances_)\n",
    "    print (sensor_list[m], model.feature_importances_[m])\n",
    "    \n",
    "    pred = model.predict(X_val)\n",
    "    \n",
    "    acc_val = accuracy_score(pred, y_val)\n",
    "    f1_val = f1_score(pred, y_val, average='weighted')\n",
    "    \n",
    "    acc_sum += acc_val\n",
    "    f1_sum += f1_val\n",
    "    \n",
    "    print (\"Fold:\", fold, \"ACC:\", acc_val, \"F1:\", f1_val)\n",
    "\n",
    "print ()\n",
    "print (\"Avg ACC:\", acc_sum / 4.0, \"Avg F1:\", f1_sum / 4.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
