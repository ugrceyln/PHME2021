{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert field names to dict for easy access.\n",
    "# Can be hard coded \n",
    "# \n",
    "fields_path = '../../input/training_validation_2/fields.csv'  \n",
    "fields_df = pd.read_csv(fields_path)\n",
    "fields_df.columns = ['name', 'f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6']\n",
    "\n",
    "fields_dict = {}\n",
    "fields_dictv2 = {}\n",
    "\n",
    "for idx in range(fields_df.shape[0]):\n",
    "    name = fields_df.loc[idx, 'name']\n",
    "\n",
    "    _fields = []\n",
    "    \n",
    "    for f in fields_df.columns[1:]:\n",
    "        if not (str(fields_df.loc[idx, f]) == 'nan'):\n",
    "            _fields.append(name + \"_\" + str(fields_df.loc[idx, f]))\n",
    "    \n",
    "    fields_dict[idx] = {'name': fields_df.loc[idx, 'name'] , 'fields': _fields}\n",
    "    fields_dictv2[name] = _fields\n",
    "    \n",
    "# fields_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LightBarrierPassiveTaskDuration1b']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = [fields_dict[29]['name']]\n",
    "feature_list_regex= \"|\".join([\"^\"+f+\"_\" for f in feature_list])\n",
    "\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data_df_1 = pd.read_csv(\"../../data/training_validation_1.csv\")\n",
    "data_df_2 = pd.read_csv(\"../../data/training_validation_2.csv\")\n",
    "merged_df = pd.concat([data_df_1, data_df_2], axis=0) # Merge data frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = merged_df.filter(regex=feature_list_regex)\n",
    "# train_df = train_df.filter(regex=\"vCnt|value\")\n",
    "# train_df = data_df_2.filter(regex=\"^Temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LightBarrierPassiveTaskDuration1b_vCnt</th>\n",
       "      <th>LightBarrierPassiveTaskDuration1b_vFreq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LightBarrierPassiveTaskDuration1b_vCnt  \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       0   \n",
       "3                                       0   \n",
       "4                                       0   \n",
       "\n",
       "   LightBarrierPassiveTaskDuration1b_vFreq  \n",
       "0                                        0  \n",
       "1                                        0  \n",
       "2                                        0  \n",
       "3                                        0  \n",
       "4                                        0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "% skip\n",
    "# All zeros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6), dpi=75)\n",
    "sns.heatmap(train_df.corr(),annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10, 8), dpi=75)\n",
    "\n",
    "\n",
    "classes = data_df_2['class'].unique()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(classes), sharex=True, figsize=(20,8))\n",
    "# fig.suptitle('1 row x 2 columns axes with no data')\n",
    "\n",
    "for idx, c in enumerate(classes):\n",
    "    df = train_df[merged_df['class'] == c].copy()\n",
    "#     df = train_df.copy()\n",
    "    sns.boxplot(data=df, ax=axes[idx])\n",
    "    axes[idx].set_title('Class '+str(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10, 8), dpi=75)\n",
    "\n",
    "\n",
    "classes = data_df_2['class'].unique()\n",
    "features = train_df.columns\n",
    "\n",
    "fig, axes = plt.subplots(len(features), len(classes), sharex=True, figsize=(30,30))\n",
    "# print (axes)\n",
    "# fig.suptitle('1 row x 2 columns axes with no data')\n",
    "\n",
    "for idx1, f in enumerate(features):\n",
    "    df = merged_df[[f, 'class']].copy()\n",
    "    for idx2, c in enumerate(classes):\n",
    "        df2 = df[df['class'] == c].copy()\n",
    "#         print (f, c, df2.columns)\n",
    "        sns.boxplot(y=df2[f], ax=axes[idx1, idx2])\n",
    "        axes[idx1, idx2].set_title('Class '+str(c))\n",
    "        axes[idx1, idx2].set_ylim(0.8*df[f].min(), 1.2*df[f].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = data_df_2['class'].unique()\n",
    "# features = train_df.columns\n",
    "\n",
    "# fig, axes = plt.subplots(len(features), 1, sharex=True, figsize=(30,16))\n",
    "\n",
    "# for idx1, f in enumerate(features):\n",
    "#     df = data_df_2[[f, 'class']].copy()\n",
    "#     axes[idx1].set_title('Feature '+str(f))\n",
    "#     for idx2, c in enumerate(classes):\n",
    "#         df2 = df[df['class'] == c].copy()\n",
    "#         axes[idx1].boxplot(x=df2[f], positions=[idx2], labels=[c])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df2 = pd.concat([data_df_2['class'], train_df], axis=1)\n",
    "# axes = train_df2.groupby('class').boxplot(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = data_df_2['class'].unique()\n",
    "features = train_df.columns\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for idx1, f in enumerate(features):\n",
    "    df = merged_df[[f, 'class']].copy()\n",
    "    data = [[\n",
    "        99, f, df[f].max(), df[f].min(), df[f].std(), df[f].mean(), df[f].median(), df[f].count(), df[f].isna().sum(),\n",
    "        ]]\n",
    "\n",
    "    data_df = pd.DataFrame(data)\n",
    "\n",
    "    df_list.append(data_df)\n",
    "\n",
    "    for idx2, c in enumerate(classes):\n",
    "        df2 = df[df['class'] == c].copy()\n",
    "\n",
    "        data = [[\n",
    "            c, f, df2[f].max(), df2[f].min(), df2[f].std(), df2[f].mean(), df2[f].median(), df2[f].count(), df2[f].isna().sum(),\n",
    "            ]]\n",
    "        \n",
    "        data_df = pd.DataFrame(data)\n",
    "        df_list.append(data_df)\n",
    "        \n",
    "new_df = pd.concat(df_list, axis=0)\n",
    "        \n",
    "new_df.columns = ['class', 'feature', 'max', 'min', 'std', 'mean', 'median', 'Count', 'NA_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[new_df['class']==99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = 0\n",
    "\n",
    "for c in classes:\n",
    "    class_df = merged_df[merged_df['class']==c]\n",
    "    runs = class_df['run'].unique()\n",
    "    for r in runs:\n",
    "        run_df = class_df[class_df['run'] == r]\n",
    "        for f in features:\n",
    "            f_df = run_df.filter([f]).copy().reset_index()\n",
    "            del f_df['index']\n",
    "            l = len(f_df)\n",
    "            n_df = f_df[f_df[f].isna()]\n",
    "#             if len(f_df) != len(n_df): print (c, r, f, len(f_df), len(n_df))\n",
    "            if (len(n_df) == 0): continue\n",
    "            missing += len(n_df)\n",
    "            for i in list(n_df.index):\n",
    "                if ((i == 0) | (i == l-1)): \n",
    "                    print ('NA at start or end')\n",
    "                else:\n",
    "                    print (c, r, f, len(f_df), list(n_df.index))\n",
    "print (missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
