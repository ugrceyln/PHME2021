{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacred import Experiment\n",
    "from sacred.commands import print_config\n",
    "from sacred.observers import FileStorageObserver\n",
    "\n",
    "ex = Experiment('PHME21', interactive=True)\n",
    "# ex.observers.append(FileStorageObserver('./lgbm_logs/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.config\n",
    "def configuration_settings():\n",
    "    fill_missing_ = True\n",
    "    scale_type = \"standard\"\n",
    "    window_size_ = 5\n",
    "    train_model = True\n",
    "    eval_model = True\n",
    "    subsample = 10 # for sampling\n",
    "    stride = 5 # for stride\n",
    "    \n",
    "    num_leaves_ = -1\n",
    "    learning_rate_ = 0.1\n",
    "    n_estimators_ = 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import data\n",
    "data_df_1 = pd.read_csv(\"../../data/imputed_training_validation_1.csv\")\n",
    "data_df_2 = pd.read_csv(\"../../data/imputed_training_validation_2.csv\")\n",
    "data_df_3 = pd.read_csv(\"../../data/imputed_model_refinement.csv\")\n",
    "\n",
    "merged_df = pd.concat([data_df_1, data_df_2, data_df_3], axis=0) # Merge data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57971, 249)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df = merged_df[~ (merged_df['class'] == 0)]\n",
    "\n",
    "train_df = merged_df.copy()\n",
    "\n",
    "train_df['runId'] = 1000 * train_df['class'] + train_df['run']\n",
    "\n",
    "labels = train_df['class']\n",
    "runs = train_df['runId']\n",
    "\n",
    "run_df = train_df[['class', 'runId']].copy()\n",
    "run_df.drop_duplicates(inplace=True)\n",
    "run_df.reset_index(inplace=True)\n",
    "del run_df['index']\n",
    "\n",
    "del train_df['run']\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_list = list(train_df.columns)\n",
    "sensor_list.remove('class')\n",
    "sensor_list.remove('runId')\n",
    "len(sensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "# from ngboost import NGBClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CpuTemperature_vMax</th>\n",
       "      <th>CpuTemperature_vMin</th>\n",
       "      <th>CpuTemperature_vStd</th>\n",
       "      <th>CpuTemperature_value</th>\n",
       "      <th>DurationPickToPick_vCnt</th>\n",
       "      <th>DurationPickToPick_vFreq</th>\n",
       "      <th>DurationPickToPick_vMax</th>\n",
       "      <th>DurationPickToPick_vMin</th>\n",
       "      <th>DurationPickToPick_vStd</th>\n",
       "      <th>DurationPickToPick_vTrend</th>\n",
       "      <th>...</th>\n",
       "      <th>NumberFuseEstimated_vTrend_na</th>\n",
       "      <th>NumberFuseEstimated_value_na</th>\n",
       "      <th>SharpnessImage_vMax_na</th>\n",
       "      <th>SharpnessImage_vMin_na</th>\n",
       "      <th>SharpnessImage_vStd_na</th>\n",
       "      <th>SharpnessImage_vTrend_na</th>\n",
       "      <th>SharpnessImage_value_na</th>\n",
       "      <th>TemperatureThermoCam_vTrend_na</th>\n",
       "      <th>class</th>\n",
       "      <th>runId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.75</td>\n",
       "      <td>44.75</td>\n",
       "      <td>3.523729</td>\n",
       "      <td>47.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.192</td>\n",
       "      <td>2.807</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.385</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.75</td>\n",
       "      <td>42.25</td>\n",
       "      <td>2.395308</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.198207</td>\n",
       "      <td>3.192</td>\n",
       "      <td>2.807</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.385</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.50</td>\n",
       "      <td>42.00</td>\n",
       "      <td>2.085815</td>\n",
       "      <td>43.825000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.296778</td>\n",
       "      <td>3.230</td>\n",
       "      <td>3.106</td>\n",
       "      <td>0.051674</td>\n",
       "      <td>0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.25</td>\n",
       "      <td>42.25</td>\n",
       "      <td>1.853375</td>\n",
       "      <td>45.200000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.298541</td>\n",
       "      <td>3.307</td>\n",
       "      <td>3.103</td>\n",
       "      <td>0.085391</td>\n",
       "      <td>0.031</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.00</td>\n",
       "      <td>42.50</td>\n",
       "      <td>2.661766</td>\n",
       "      <td>45.700000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.298554</td>\n",
       "      <td>3.242</td>\n",
       "      <td>3.153</td>\n",
       "      <td>0.038577</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CpuTemperature_vMax  CpuTemperature_vMin  CpuTemperature_vStd  \\\n",
       "0                56.75                44.75             3.523729   \n",
       "1                48.75                42.25             2.395308   \n",
       "2                47.50                42.00             2.085815   \n",
       "3                48.25                42.25             1.853375   \n",
       "4                50.00                42.50             2.661766   \n",
       "\n",
       "   CpuTemperature_value  DurationPickToPick_vCnt  DurationPickToPick_vFreq  \\\n",
       "0             47.833333                      0.0                  0.000000   \n",
       "1             45.000000                      2.0                  0.198207   \n",
       "2             43.825000                      3.0                  0.296778   \n",
       "3             45.200000                      3.0                  0.298541   \n",
       "4             45.700000                      3.0                  0.298554   \n",
       "\n",
       "   DurationPickToPick_vMax  DurationPickToPick_vMin  DurationPickToPick_vStd  \\\n",
       "0                    3.192                    2.807                 0.192500   \n",
       "1                    3.192                    2.807                 0.192500   \n",
       "2                    3.230                    3.106                 0.051674   \n",
       "3                    3.307                    3.103                 0.085391   \n",
       "4                    3.242                    3.153                 0.038577   \n",
       "\n",
       "   DurationPickToPick_vTrend  ...  NumberFuseEstimated_vTrend_na  \\\n",
       "0                      0.385  ...                              1   \n",
       "1                      0.385  ...                              0   \n",
       "2                      0.020  ...                              1   \n",
       "3                      0.031  ...                              1   \n",
       "4                     -0.036  ...                              1   \n",
       "\n",
       "   NumberFuseEstimated_value_na  SharpnessImage_vMax_na  \\\n",
       "0                             1                       1   \n",
       "1                             0                       0   \n",
       "2                             1                       1   \n",
       "3                             1                       1   \n",
       "4                             1                       1   \n",
       "\n",
       "   SharpnessImage_vMin_na  SharpnessImage_vStd_na  SharpnessImage_vTrend_na  \\\n",
       "0                       1                       1                         1   \n",
       "1                       0                       0                         0   \n",
       "2                       1                       1                         1   \n",
       "3                       1                       1                         1   \n",
       "4                       1                       1                         1   \n",
       "\n",
       "   SharpnessImage_value_na  TemperatureThermoCam_vTrend_na  class  runId  \n",
       "0                        1                               1      0      0  \n",
       "1                        0                               0      0      0  \n",
       "2                        1                               0      0      0  \n",
       "3                        1                               0      0      0  \n",
       "4                        1                               0      0      0  \n",
       "\n",
       "[5 rows x 249 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def create_sequence(sequence, n_steps):\n",
    "    X = list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x = sequence[i:end_ix]\n",
    "        X.append(seq_x)\n",
    "    return np.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_for_run(df, ws):\n",
    "#     data_data = np.empty((0, ws * len(sensor_list))) # for 1D\n",
    "#     data_data = np.empty((0, ws, len(sensor_list))) # for 2D\n",
    "#     data_data = np.empty((0, len(sensor_list), ws)) # for 2D\n",
    "#     label_data = np.empty((0, 1))\n",
    "\n",
    "    sensors_df = df.filter(sensor_list)\n",
    "\n",
    "    # Calculate seq of windows_size len\n",
    "    seq = create_sequence(sensors_df.values, n_steps=ws)\n",
    "#     seq = np.transpose(seq, axes=(0, 2, 1))\n",
    "    seq_count = seq.shape[0]\n",
    "    seq = seq.reshape((seq_count, -1)) # for 1D\n",
    "    seq = seq[::ws//2]\n",
    "    \n",
    "    # add new seq to data_data array\n",
    "#     data_data = np.vstack((data_data, seq))\n",
    "\n",
    "    # Calculate RULS\n",
    "    labels = df['class'].values[:seq_count]\n",
    "    labels = labels[::ws//2]\n",
    "\n",
    "    # add rul to rul_data array\n",
    "#     rul_data = np.vstack((rul_data, ruls))\n",
    "\n",
    "# TODO: What is RUL_Max in this context?\n",
    "\n",
    "#     print (\"Shape:\", seq.shape, labels.shape)\n",
    "    return seq, labels\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "\n",
    "# Main sensor list. \n",
    "# List shall include other features such as operating conditions. \n",
    "_subsample = -1\n",
    "_stride = -1\n",
    "\n",
    "# scale_type = \"standard\"\n",
    "# window_size = 50\n",
    "# cv_fold = 3\n",
    "\n",
    "# train_model = True\n",
    "# eval_model = True\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: X_t, X_tp1, y_t, y_tp1 should be calculated per run.  \n",
    "# TODO: Then should be merged into one X_t, X_tp1, y_t, y_tp1.\n",
    "def create_datasets(df, ws):\n",
    "    \n",
    "    run_list = df['runId'].unique()\n",
    "\n",
    "    X_df_list = []\n",
    "    y_df_list = []\n",
    "    \n",
    "    for r in run_list:\n",
    "        r_df = df[df['runId'] == r]\n",
    "#         print (\"--> r: \", r, r_df.shape)\n",
    "        sensor_data, label_data = create_dataset_for_run(r_df, ws)\n",
    "\n",
    "        # Post Processing for the model\n",
    "\n",
    "        # Padding for model input \n",
    "        padded_sensor_data = sensor_data.copy() #np.hstack((sensor_data, np.zeros((sensor_data.shape[0], 2)))) # for AE     \n",
    "\n",
    "        # Calculate X(t) and X(t+1) for model input/output \n",
    "        X_t = padded_sensor_data[:]\n",
    "\n",
    "        # Calculate y(t) and y(t+1) for model input/output \n",
    "        y_t = label_data[:]\n",
    "\n",
    "        X_df_list.append(pd.DataFrame(X_t))\n",
    "        y_df_list.append(pd.DataFrame(y_t))\n",
    "    \n",
    "    X_t = pd.concat(X_df_list, axis=0) # Merge data frames\n",
    "    y_t = pd.concat(y_df_list, axis=0) # Merge data frames\n",
    "\n",
    "    return X_t.values, y_t.values.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = StratifiedKFold(n_splits=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_list = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.main\n",
    "def ex_main(_run, fill_missing_, scale_type, window_size_, train_model, eval_model, subsample, stride, num_leaves_, learning_rate_, n_estimators_):\n",
    "\n",
    "    global total_runs\n",
    "    global run_counter\n",
    "    global results_df\n",
    "    \n",
    "    print ('===========================================================================')\n",
    "    print ('Run:', run_counter+1, '/', total_runs)\n",
    "    print (\"Window Size:\", window_size_)\n",
    "\n",
    "    run_counter += 1\n",
    "    \n",
    "    acc_sum = 0\n",
    "    f1_sum = 0\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "    for fold, (training_indices, validation_indices) in enumerate(cv.split(run_df['runId'], run_df['class'])):\n",
    "        print (\"--> Fold: \", fold)\n",
    "\n",
    "        training_runIds = run_df.loc[training_indices]['runId']\n",
    "        validation_runIds = run_df.loc[validation_indices]['runId']\n",
    "\n",
    "        X_train_df = train_df[train_df['runId'].isin(training_runIds)].copy()\n",
    "        X_val_df = train_df[train_df['runId'].isin(validation_runIds)].copy()\n",
    "\n",
    "        X_train, y_train = create_datasets(X_train_df, window_size_)\n",
    "        X_val, y_val = create_datasets(X_val_df, window_size_)\n",
    "\n",
    "    #     print (\"Data shape\", X_train_df.shape, X_val_df.shape)\n",
    "        print (\"Train data shape:\", X_train.shape, y_train.shape)\n",
    "        print (\"Val data shape:\", X_val.shape, y_val.shape)\n",
    "\n",
    "        xgb_model = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            XGBClassifier()\n",
    "        )\n",
    "\n",
    "        lgbm_1_model = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            LGBMClassifier()\n",
    "        )\n",
    "\n",
    "        lgbm_2_model = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            LGBMClassifier(num_leaves=5, learning_rate=0.01, n_estimators=200)\n",
    "        )\n",
    "\n",
    "        svm_model = make_pipeline(\n",
    "            StandardScaler(), \n",
    "            PCA(n_components=21), \n",
    "            SVC(class_weight='balanced', gamma='auto')\n",
    "        )        \n",
    "\n",
    "        gnb_model = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            PCA(n_components=21), \n",
    "            GaussianNB()\n",
    "        )\n",
    "        \n",
    "        voting_clf = VotingClassifier(\n",
    "            estimators=[\n",
    "                ('xgb', xgb_model), \n",
    "                ('lgbm1', lgbm_1_model), \n",
    "#                 ('lgbm2', lgbm_2_model), \n",
    "                ('svm', svm_model), \n",
    "#                 ('gnb', gnb_model)\n",
    "            ], voting='hard', verbose=True, n_jobs=6)            \n",
    "        \n",
    "        voting_clf.fit(X_train, y_train)\n",
    "\n",
    "        pred = voting_clf.predict(X_val)\n",
    "\n",
    "        acc_val = accuracy_score(pred, y_val)\n",
    "        f1_val = f1_score(pred, y_val, average='weighted')\n",
    "\n",
    "        acc_sum += acc_val\n",
    "        f1_sum += f1_val\n",
    "\n",
    "        print (\"Fold:\", fold, \"ACC:\", acc_val, \"F1:\", f1_val)\n",
    "\n",
    "    print ()\n",
    "    print (\"Avg ACC:\", acc_sum / 3.0, \"Avg F1:\", f1_sum / 3.0)\n",
    "\n",
    "    result = {\n",
    "        'ML_Algorithm': 'voting',\n",
    "        'Window Size': window_size_, \n",
    "        'ACC': acc_sum / 3.0,\n",
    "        'F1': f1_sum / 3.0,\n",
    "    }\n",
    "\n",
    "    results_df = results_df.append(result, ignore_index=True)\n",
    "    results_df.to_excel(\"voting_results.xlsx\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - PHME21 - No observers have been added to this run\n",
      "INFO - PHME21 - Running command 'ex_main'\n",
      "INFO - PHME21 - Started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "Run: 1 / 11\n",
      "Window Size: 5\n",
      "--> Fold:  0\n",
      "Train data shape: (19318, 1235) (19318,)\n",
      "Val data shape: (9495, 1235) (9495,)\n"
     ]
    }
   ],
   "source": [
    "run_counter = 0\n",
    "total_runs = len(ws_list)\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for wsl in ws_list:\n",
    "    ex.run(config_updates={\n",
    "        'window_size_': wsl,\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "fill_missing_ = True\n",
    "window_size_ = 200\n",
    "num_leaves_ = 4\n",
    "learning_rate_ = 0.1\n",
    "n_estimators_ = 500\n",
    "\n",
    "for fold, (training_indices, validation_indices) in enumerate(cv.split(run_df['runId'], run_df['class'])):\n",
    "    print (\"--> Fold: \", fold)\n",
    "\n",
    "    training_runIds = run_df.loc[training_indices]['runId']\n",
    "    validation_runIds = run_df.loc[validation_indices]['runId']\n",
    "\n",
    "    X_train_df = train_df[train_df['runId'].isin(training_runIds)].copy()\n",
    "    X_val_df = train_df[train_df['runId'].isin(validation_runIds)].copy()\n",
    "\n",
    "    if (fill_missing_):\n",
    "        X_train_df.fillna(method='backfill', inplace=True)\n",
    "        X_val_df.fillna(method='backfill', inplace=True)\n",
    "\n",
    "        X_train_df.fillna(-1, inplace=True)\n",
    "        X_val_df.fillna(-1, inplace=True)\n",
    "\n",
    "    X_train, y_train = create_datasets(X_train_df, window_size_)\n",
    "    X_val, y_val = create_datasets(X_val_df, window_size_)\n",
    "\n",
    "#     print (\"Data shape\", X_train_df.shape, X_val_df.shape)\n",
    "    print (\"Train data shape:\", X_train.shape, y_train.shape)\n",
    "    print (\"Val data shape:\", X_val.shape, y_val.shape)\n",
    "\n",
    "    model = LGBMClassifier(num_leaves=num_leaves_, learning_rate=learning_rate_, n_estimators=n_estimators_)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
