{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from lofo import LOFOImportance, Dataset, plot_importance\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data_df_1 = pd.read_csv(\"../../data/imputed_training_validation_1.csv\")\n",
    "data_df_2 = pd.read_csv(\"../../data/imputed_training_validation_2.csv\")\n",
    "data_df_3 = pd.read_csv(\"../../data/imputed_model_refinement.csv\")\n",
    "\n",
    "merged_df = pd.concat([data_df_1, data_df_2, data_df_3], axis=0) # Merge data frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = merged_df.filter(regex=\"vCnt|value|class|run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_list = list(train_df.columns)\n",
    "sensor_list.remove('class')\n",
    "sensor_list.remove('run')\n",
    "len(sensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def create_sequence(sequence, n_steps):\n",
    "    X = list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x = sequence[i:end_ix]\n",
    "        X.append(seq_x)\n",
    "    return np.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_for_run(df, ws):\n",
    "#     data_data = np.empty((0, ws * len(sensor_list))) # for 1D\n",
    "#     data_data = np.empty((0, ws, len(sensor_list))) # for 2D\n",
    "#     data_data = np.empty((0, len(sensor_list), ws)) # for 2D\n",
    "#     label_data = np.empty((0, 1))\n",
    "\n",
    "    sensors_df = df.filter(sensor_list)\n",
    "\n",
    "    # Calculate seq of windows_size len\n",
    "    seq = create_sequence(sensors_df.values, n_steps=ws)\n",
    "#     seq = np.transpose(seq, axes=(0, 2, 1))\n",
    "    seq_count = seq.shape[0]\n",
    "    seq = seq.reshape((seq_count, -1)) # for 1D\n",
    "\n",
    "    # add new seq to data_data array\n",
    "#     data_data = np.vstack((data_data, seq))\n",
    "\n",
    "    # Calculate RULS\n",
    "    labels = df['class'].values[:seq_count]\n",
    "\n",
    "    # add rul to rul_data array\n",
    "#     rul_data = np.vstack((rul_data, ruls))\n",
    "\n",
    "# TODO: What is RUL_Max in this context?\n",
    "\n",
    "#     print (\"Shape:\", seq.shape, labels.shape)\n",
    "    return seq, labels\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: X_t, X_tp1, y_t, y_tp1 should be calculated per run.  \n",
    "# TODO: Then should be merged into one X_t, X_tp1, y_t, y_tp1.\n",
    "def create_datasets(df, ws):\n",
    "    c = int(df.iloc[0]['class'])\n",
    "    r = int(df.iloc[0]['run'])\n",
    "    \n",
    "#     print (c, r)\n",
    "    \n",
    "    sensor_data, label_data = create_dataset_for_run(df, ws)\n",
    "\n",
    "    # Post Processing for the model\n",
    "\n",
    "    # Padding for model input \n",
    "    padded_sensor_data = sensor_data.copy() #np.hstack((sensor_data, np.zeros((sensor_data.shape[0], 2)))) # for AE     \n",
    "\n",
    "    # Calculate X(t) and X(t+1) for model input/output \n",
    "    X_t = padded_sensor_data[:]\n",
    "\n",
    "    # Calculate y(t) and y(t+1) for model input/output \n",
    "    y_t = label_data[:]\n",
    "\n",
    "    return pd.DataFrame(X_t) #, y_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols1 = [ \"_\".join([str(c),str(0)]) for i, c in enumerate(sensor_list)]\n",
    "cols2 = [ \"_\".join([str(c),str(1)]) for i, c in enumerate(sensor_list)]\n",
    "cols = ['class'] + cols1 + cols2\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = 2\n",
    "new_df = train_df.groupby(['class', 'run']).apply(create_datasets, ws)\n",
    "new_df.reset_index(inplace=True)\n",
    "del new_df['level_2']\n",
    "del new_df['run']\n",
    "new_df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a sample of the data\n",
    "sample_df = new_df.sample(frac=0.5, random_state=42)\n",
    "#sample_df.sort_values(\"run\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the validation scheme\n",
    "cv = KFold(n_splits=3, shuffle=True)\n",
    "# cv = StratifiedKFold(n_splits=4, shuffle=False, random_state=0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the binary target and the features\n",
    "dataset = Dataset(df=sample_df, target=\"class\", features=[col for col in sample_df.columns if col != 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(StandardScaler(), PCA(n_components=0.9995), SVC(class_weight='balanced', gamma='auto'))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the validation scheme and scorer. The default model is LightGBM\n",
    "lofo_imp = LOFOImportance(dataset, cv=cv, model=model, scoring=\"f1_micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mean and standard deviation of the importances in pandas format\n",
    "importance_df = lofo_imp.get_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the means and standard deviations of the importances\n",
    "plot_importance(importance_df, figsize=(12, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(sorted([x[:-2] for x in list(importance_df[importance_df.importance_mean>0].feature)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
