{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import nan\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import collections\n",
    "from collections import defaultdict \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert field names to dict for easy access.\n",
    "# Can be hard coded \n",
    "# \n",
    "fields_path = '../../input/training_validation_2/fields.csv'  \n",
    "fields_df = pd.read_csv(fields_path)\n",
    "fields_df.columns = ['name', 'f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6']\n",
    "\n",
    "fields_dict = {}\n",
    "\n",
    "for idx in range(fields_df.shape[0]):\n",
    "    name = fields_df.loc[idx, 'name']\n",
    "\n",
    "    _fields = []\n",
    "    \n",
    "    for f in fields_df.columns[1:]:\n",
    "        if not (str(fields_df.loc[idx, f]) == 'nan'):\n",
    "            _fields.append(name + \"_\" + str(fields_df.loc[idx, f]))\n",
    "    \n",
    "    fields_dict[idx] = {'name': fields_df.loc[idx, 'name'] , 'fields': _fields}\n",
    "\n",
    "fields_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feautures that have more than 10% missing values:\n",
    "features_with_10p_na = [\n",
    "    'DurationRobotFromTestBenchToFeeder_vTrend', 'FeederBackgroundIlluminationIntensity_vMax',\n",
    "    'FeederBackgroundIlluminationIntensity_vMin', 'FeederBackgroundIlluminationIntensity_vStd',\n",
    "    'FeederBackgroundIlluminationIntensity_vTrend', 'FeederBackgroundIlluminationIntensity_value', \n",
    "    'FuseHeatSlope_vTrend', 'FuseHeatSlopeNOK_vMax', 'FuseHeatSlopeNOK_vMin', 'FuseHeatSlopeNOK_vStd', \n",
    "    'FuseHeatSlopeNOK_vTrend', 'FuseHeatSlopeNOK_value', 'FuseHeatSlopeOK_vMax', 'FuseHeatSlopeOK_vMin', \n",
    "    'FuseHeatSlopeOK_vStd', 'FuseHeatSlopeOK_vTrend', 'FuseHeatSlopeOK_value', 'IntensityTotalImage_vMax', \n",
    "    'IntensityTotalImage_vMin', 'IntensityTotalImage_vStd', 'IntensityTotalImage_vTrend', 'IntensityTotalImage_value', \n",
    "    'IntensityTotalThermoImage_vTrend', 'NumberFuseDetected_vMax', 'NumberFuseDetected_vMin', 'NumberFuseDetected_vStd', \n",
    "    'NumberFuseDetected_vTrend', 'NumberFuseDetected_value', 'NumberFuseEstimated_vMax', 'NumberFuseEstimated_vMin', \n",
    "    'NumberFuseEstimated_vStd', 'NumberFuseEstimated_vTrend', 'NumberFuseEstimated_value', 'SharpnessImage_vMax', \n",
    "    'SharpnessImage_vMin', 'SharpnessImage_vStd', 'SharpnessImage_vTrend', 'SharpnessImage_value', \n",
    "    'TemperatureThermoCam_vTrend'\n",
    "]\n",
    "\n",
    "len(features_with_10p_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feautures that have more than 20% missing values:\n",
    "features_with_20p_na = [\n",
    "    'FeederBackgroundIlluminationIntensity_vMax', 'FeederBackgroundIlluminationIntensity_vMin',\n",
    "    'FeederBackgroundIlluminationIntensity_vStd', 'FeederBackgroundIlluminationIntensity_vTrend',\n",
    "    'FeederBackgroundIlluminationIntensity_value', 'FuseHeatSlope_vTrend', 'FuseHeatSlopeNOK_vTrend', \n",
    "    'FuseHeatSlopeOK_vMax', 'FuseHeatSlopeOK_vMin', 'FuseHeatSlopeOK_vStd', 'FuseHeatSlopeOK_vTrend', \n",
    "    'FuseHeatSlopeOK_value', 'IntensityTotalImage_vMax', 'IntensityTotalImage_vMin', 'IntensityTotalImage_vStd', \n",
    "    'IntensityTotalImage_vTrend', 'IntensityTotalImage_value', 'IntensityTotalThermoImage_vTrend', \n",
    "    'NumberFuseDetected_vMax', 'NumberFuseDetected_vMin', 'NumberFuseDetected_vStd', 'NumberFuseDetected_vTrend',\n",
    "    'NumberFuseDetected_value', 'NumberFuseEstimated_vMax', 'NumberFuseEstimated_vMin', 'NumberFuseEstimated_vStd',\n",
    "    'NumberFuseEstimated_vTrend', 'NumberFuseEstimated_value', 'SharpnessImage_vMax', 'SharpnessImage_vMin', \n",
    "    'SharpnessImage_vStd', 'SharpnessImage_vTrend', 'SharpnessImage_value', 'TemperatureThermoCam_vTrend'\n",
    "]\n",
    "\n",
    "len(features_with_20p_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(features_with_10p_na).difference(set(features_with_20p_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class id and run id from filename\n",
    "def parse_class_name(fname):\n",
    "    p = re.compile(\"^class[^\\d]*(\\d+)_(\\d+).*.csv\")\n",
    "    m = p.match(fname)\n",
    "    \n",
    "    return m.groups()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_df(df):\n",
    "    \n",
    "#     for f in features_with_20p_na:\n",
    "#         new_f_name = f + \"_na\"\n",
    "#         df[new_f_name] = df[f].isna().astype(np.int32)\n",
    "    \n",
    "#         del df[f]\n",
    "\n",
    "    df = df.interpolate(limit_direction='both')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one data file and return in a data frame\n",
    "def load_data_file(path, fname):\n",
    "    fullpath = join(path,fname)\n",
    "    df = pd.read_csv(fullpath)\n",
    "    df.columns = ['name', 'data']\n",
    "    \n",
    "    dfx = []\n",
    "    \n",
    "    for f in fields_dict:\n",
    "        name = fields_dict[f]['name']\n",
    "        fields = fields_dict[f]['fields']\n",
    "        \n",
    "        data = eval(df.loc[f,'data']) # convert data to array\n",
    "        \n",
    "        new_df = pd.DataFrame(data)\n",
    "        if (f==33) and (new_df.shape[1] == 6): # NumberFuseDetected has a special case!\n",
    "            new_df[6] = new_df[5]\n",
    "            new_df[5] = np.NaN\n",
    "            \n",
    "\n",
    "        new_df.columns = fields_dict[f]['fields']\n",
    "        \n",
    "        dfx.append(new_df)\n",
    "        \n",
    "    merged_df = pd.concat(dfx, axis=1) # Merge columns\n",
    "    \n",
    "# Do some imputation on the data file\n",
    "    merged_df = impute_df(merged_df.copy())\n",
    "\n",
    "    c, r = parse_class_name(fname) # Get class id and run id\n",
    "\n",
    "    # Add class labels and run id\n",
    "    merged_df['class'] = int(c)\n",
    "    merged_df['run'] = int(r)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data files from a directory and return merged data frame\n",
    "def load_data_files(path):\n",
    "    \n",
    "    print (\"In\", path)\n",
    "    files = [] \n",
    "    for f in listdir(path):\n",
    "        if (isfile(join(path, f)) and (f.startswith(\"class\"))):\n",
    "            files.append(f)\n",
    "    \n",
    "    data_df_list = []\n",
    "    for fname in files:\n",
    "        print (\"Loading:\", fname)\n",
    "        \n",
    "        df = load_data_file(path, fname)\n",
    "        \n",
    "        data_df_list.append(df)\n",
    "\n",
    "    data_df = pd.concat(data_df_list, axis=0) # Merge data frames\n",
    "    \n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_df_1 = load_data_files(\"../../input/training_validation_1/\")\n",
    "data_df_2 = load_data_files(\"../../input/training_validation_2/\")\n",
    "data_df_3 = load_data_files(\"../../input/ModelRefinement/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to store data frames\n",
    "\n",
    "data_df_1.to_csv(\"../../data/interpolated_training_validation_1.csv\", index=False)\n",
    "data_df_2.to_csv(\"../../data/interpolated_training_validation_2.csv\", index=False)\n",
    "data_df_3.to_csv(\"../../data/interpolated_model_refinement.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
